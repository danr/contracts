To formalise the ideas behind our implementation, we define a
tiny source language $\cal L$:
a polymorphic, higher-order, call-by-name $\lambda$-calculus with
algebraic datatypes, pattern matching, and recursion.
Our actual implementation treats all of Haskell, by using GHC as a front
end to translate Haskell into language $\cal L$.

\subsection{Syntax of $\cal L$} \label{s:syntax}

\begin{figure}
\[\begin{array}{l}
\begin{array}{lrll}
\multicolumn{4}{l}{\text{Programs, definitions, and expressions}} \\
P   & ::= & d_1 \ldots d_n \\
d   & ::= & f\; \ol{a} \; \ol{(x\!:\!\tau)} = u \\
u   & ::= & \multicolumn{2}{l}{e \; \mid \; @case@\;e\;@of@\;\ol{K\;\ol{y} -> e}} \\
e  & ::=  & x            & \text{Variables} \\
   & \mid & f[\ol{\tau}] & \text{Function variables} \\
   & \mid & K[\ol{\tau}](\ol{e}) & \text{Data constructors (saturated)} \\
   & \mid & e\;e         & \text{Applications} \\
   & \mid & @BAD@        & \text{Runtime error} \\
\end{array}\\ \\
\begin{array}{lrll}
\multicolumn{3}{l}{\text{Syntax of closed values}} \\
 v,w & ::= & K^\ar[\ol{\tau}](\oln{e}{\ar}) \;\mid\; f^\ar[\ol{\tau}]\;\oln{e}{m < \ar} \;\mid\; @BAD@ \\ \\
\end{array}
\\
\begin{array}{lrll}
\multicolumn{3}{l}{\text{Contracts}} \\
 \Ct & ::=  & \{ x \mid e \}        & \text{Base contracts}  \\
     & \mid &  (x : \Ct_1) -> \Ct_2      & \text{Arrow contracts} \\
     & \mid & \Ct_1 \& \Ct_2             & \text{Conjunctions}   \\
     & \mid & \CF                        & \text{Crash-freedom}   \\
\end{array}
\\ \\
\begin{array}{lrll}
\multicolumn{3}{l}{\text{Types}} \\
\tau,\sigma & ::=  & T\;\taus & \text{Datatypes} \\
            & \mid & a \mid \tau -> \tau
\end{array}
\\ \\
\begin{array}{lrll}
\multicolumn{3}{l}{\text{Type environments and signatures}} \\
\Gamma & ::=  & \cdot \mid \Gamma,x \\
\Delta & ::=  & \cdot \mid \Delta,a \mid \Delta,x{:}\tau \\
\Sigma & ::=  & \cdot \mid \Sigma,T{:}n \mid \Sigma,f{:}\forall\ol{a} @.@ \tau \mid \Sigma,K^{\ar}{:}\forall\ol{a} @.@ \oln{\tau}{\ar} -> @T@\;\as
\end{array}
\\ \\
\begin{array}{lrll}
\multicolumn{3}{l}{\text{Auxiliary functions}} \\
%% constrs(\Sigma,T) & = & \{ K \mid (K{:}\forall \as @.@ \taus -> T\;\as) \in \Sigma \} \\
(\cdot)^{-}            & = & \cdot \\
(\Delta,a)^{-}         & = & \Delta^{-} \\
(\Delta,(x{:}\tau))^{-} & = & \Delta^{-},x
%% \tyar{D}{f} & = & n & \\
%%             & \multicolumn{3}{l}{\text{when}\; (f |-> \Lambda\oln{a}{n} @.@ \lambda\ol{x{:}\tau} @.@ u) \in D} \\
%% \tmar{D}{f} & = & n & \\
%%             & \multicolumn{3}{l}{\text{when}\; (f |-> \Lambda\ol{a} @.@ \lambda\oln{x{:}\tau}{n} @.@ u) \in D}
\end{array}
\end{array}\]
\caption{Syntax of $\cal L$ and its contracts}\label{fig:syntax}
\end{figure}

Figure~\ref{fig:syntax} presents the syntax of $\cal L$.  A program
$P$ consists of a set of recursive function definitions $d_1 \ldots
d_n$. Each definition has a left hand side that binds its type-variable and
term-variable parameters;
if $f$ has $n$ term-variable parameters we say that
it has arity $n$, and sometimes write it $f^n$.
The right hand side $u$ of a definition is either a @case@ expression or a
@case@-free expression $e$.  A @case@-free expression consists of
variables $x$, function variables $f[\taus]$ fully applied to their
type arguments, applications $e_1\;e_2$, data constructor applications
$K[\taus](\ol{e})$. As a notation, we use
$\oln{x}{n}$ for sequences of elements of size $n$. When $n$ is
omitted $\ol{x}$ has a size which is implied by the context or is not
interesting.

A program \emph{crashes} if it evaluates the special value @BAD@.
For example, we assume that the standard Haskell function @error@
simply invokes @BAD@, thus:
\begin{code}
  error :: String -> a
  error s = BAD
\end{code}
Moreover, we assume that all incomplete pattern-matches are completed, with the
missing case yielding @BAD@.  For example:
\begin{code}
  head :: [a] -> [a]
  head (x:xs) = x
  head []     = BAD
\end{code}
In our context, @BAD@ is our way to saying what it means for a program to ``go wrong'',
and verification amounts to proving that a program cannot invoke @BAD@.

Our language embodies several convenient syntactic constraints:
(i)~$\lambda$ abstractions occur only at the top-level,
(ii)~@case@-expressions can only immediately follow a function
definition, and (iii) constructors are fully applied.
Any Haskell program can be transformed into this restricted
form using lambda-lifting, @case@-lifting, and eta-expansion respectively,
and our working prototype does just this.
However this simpler language is instead extremely
convenient for the translation of programs to first-order logic.

$\cal L$ is an explicitly-typed language, and we assume the existence
of a typing relation $\Sigma |- P$, which checks that a program
conforms to the definitions in the signature $\Sigma$. A signature
$\Sigma$ (Figure~\ref{fig:syntax}) records the declared data types,
data constructors and types of functions in the program $P$. The
well-formedness of expressions is checked with a typing relation
$\Sigma;\Delta |- u : \tau$, where $\Delta$ is a typing environment,
also in Figure~\ref{fig:syntax}.  We do not give the details of the
typing relation since it is standard.
Our technical development and analysis in the following sections
assume that programs have been checked for type errors.
The typing judgement should check that all pattern matches are
exhaustive; as mentioned above, missing cases should return @BAD@.

The syntax of closed values is also given in Figure~\ref{fig:syntax}. Since we do not
have arbitrary $\lambda$-abstractions, values can only be partial function applications
$f^\ar[\ol{\tau}]\;\oln{e}{m < \ar}$, data constructor applications $K[\tau](\ol{e})$,
and the error term @BAD@.

The operational semantics of $\cal L$ is entirely standard, and we do not give it here.
We write $P |- u \Downarrow v$ to mean ``In program P, right-hand side $u$ evaluates to
value $v$'',

% -------------------- Omitted section on operational semantics ------------
% \subsection{Operational semantics of $\cal L$}
%
% \spj{Why do we give an operational as well as denotational semantics?}
% The big-step operational semantics of our language is given in
% Figure~\ref{fig:opsem}, which contains no surprises. One interesting
% detail of big-step semantics is that they do not distinguish between non-termination
% and ``getting stuck'', meaning that if $P \not|- e \Downarrow v$ then $e$ could either diverge or its
% evaluation could get stuck. We return to this convenient for our purposes form of operational
% semantics later. \spj{Where later? Also this sentence is hard to parse; indeed I'm not quite
% sure what it means.}
% \begin{figure}
% \[\begin{array}{c}
% \ruleform{P |- u \Downarrow v} \\
% \prooftree
% \begin{array}{c} \ \\
% \end{array}
% -------------------------------------{EVal}
% P |- v \Downarrow v
% ~~~~~
% \begin{array}{c}
% (f \;\ol{a}\;\oln{(x{:}\tau)}{m} = u) \in P \\
% P |- u[\ol{\tau}/\ol{a}][\ol{e}/\ol{x}] \Downarrow v
% \end{array}
% -------------------------------------{EFun}
% P |- f[\ol{\tau}]\;\oln{e}{m} \Downarrow v
% ~~~~~
% \begin{array}{c}
% P |- e_1 \Downarrow v_1 \\
% P |- v_1\;e_2 \Downarrow w
% \end{array}
% ------------------------------------------------{EApp}
% P |- e_1\;e_2 \Downarrow w
% ~~~~~
% \begin{array}{c}
% P |- e_1 \Downarrow @BAD@
% \end{array}
% ------------------------------------------------{EBadApp}
% P |- e_1\;e_2 \Downarrow @BAD@
% ~~~~~
% %% \endprooftree \\ \\
% %% \ruleform{P |- u \Downarrow v} \\ \\
% %% \prooftree
% %% P |- e \Downarrow v
% %% -------------------------------------{EUTm}
% %% P |- e \Downarrow v
% %% ~~~~
% \begin{array}{c}
% P |- e \Downarrow K_i[\ol{\sigma}_i](\ol{e}_i) \quad
% P |- e'_i[\ol{e}_i/\ol{y}_i] \Downarrow w
% \end{array}
% ------------------------------------{ECase}
% P |- @case@\;e\;@of@\;\ol{K\;\ol{y} -> e'} \Downarrow w
% ~~~~~
% \begin{array}{c}
% P |- e \Downarrow @BAD@ \\
% \end{array}
% ------------------------------------{EBadCase}
% P |- @case@\;e\;@of@\;\ol{K\;\ol{y} -> e'} \Downarrow @BAD@
% %% \begin{array}{c}
% %% (f |-> \Lambda\ol{a} @.@ \lambda\oln{x{:}\tau}{m} @.@ @case@\;e\;@of@\;\ol{K\;\ol{y} -> e'}) \in D \\
% %% D |- e[\ol{\tau}/\ol{a}][\ol{e}/\ol{x}] \Downarrow @BAD@ \\
% %% \end{array}
% %% -------------------------------------{EBadCase}
% %% D |- f[\ol{\tau}]\;\oln{e}{m} \Downarrow @BAD@
% \endprooftree
% \end{array}\]
% \caption{Operational semantics of $\cal L$}\label{fig:opsem}
% \end{figure}
% %% We can state some standard properties of the typing and evaluation relation.
% %% \begin{lemma}[Subject reduction]
% %% Assume $\Sigma |- P$ and $\Sigma;\cdot |- e : \tau$
% %% If $P |- e \Downarrow w$ then $P |- value(w)$ and $\Sigma;\cdot |- w : \tau$.
% %% \end{lemma}
% The operational semantics of Figure~\ref{fig:opsem} has the possibility of non-determinism because
% of the overlapping of several rules for applications. But that is not a problem, as we can prove that evaluation
% is deterministic using the following two lemmas.
% \begin{lemma}[Value determinacy]
% If $\Sigma;\cdot |- v : \tau$ and
% $\Sigma |- P$ and $P |- v \Downarrow w$ then $ v = w $.
% \end{lemma}
% \begin{lemma}[Determinacy of evaluation]
% If $\Sigma;\cdot |- e : \tau$ and
% $\Sigma |- P$ and $\Sigma;\cdot |- e \Downarrow v_1$ and $\Sigma;\cdot |- e \Downarrow v_2$ then
% $v_1 = v_2$.
% \end{lemma}
% Finally, big-step soundness asserts that an expression that evaluates results in a
% well-typed value.
% \begin{lemma}[Big-step soundness]
% If $\Sigma;\cdot |- e : \tau$ and
% $\Sigma |- P$ and $\Sigma;\cdot |- e \Downarrow v$ then $\Sigma;\cdot |- v : \tau$.
% \end{lemma}

\subsection{Contracts}

% \begin{figure}
% \[\begin{array}{lcl}
% e \in \{ x \mid e_p\} & <=> &  e \not\Downarrow \text{ or } e_p[e/x] \not\Downarrow \text{ or} \\
%                         &     &  e_p[e/x] \Downarrow True \\
% e \in (x{:}\Ct_1) -> \Ct_2 & <=> &
%                         \forall e' \in \Ct_1.\; (e\;e') \in \Ct_2[e'/x] \\
% e \in \Ct_1 \& \Ct_2 & <=> & e \in \Ct_1 \text{ and } e \in \Ct_2 \\
% e \in \CF            & <=> & \forall {\cal C}. BAD \not\in {\cal C} \Rightarrow e \not\Downarrow BAD
% \end{array}
% \]
% \caption{Operational semantics of contracts} \label{f:contract-spec-op}
% \end{figure}

We now turn our attention to contracts. The syntax of contracts
is given in Figure~\ref{fig:syntax} and includes base contracts
$\{ x \mid e \}$, arrow contracts $(x : \Ct_1) -> \Ct_2$, conjunctions
$\Ct_1 \& \Ct_2$ and crash-freedom $\CF$. Previous work~\cite{xu+:contracts}
includes other constructs as well, but the constructs we give here are enough to verify
many programs and exhibit the interesting theoretical and practical problems.

We write $e \in C$ to mean ``the expression $e$ satisfies the contract $C$'', and similarly
for functions $f$.  We will say what contracts mean formally in
Section~\ref{s:den-sem-contracts}.  However, here is their informal meaning:
\begin{itemize}
\item $e \in \{x | e'\}$ if $e$ diverges or $e[e'/x]$ evaluates to @True@ or diverges.
Notice that $e'$ is an arbitrary expression
(in our implementation, arbitrary Haskell expressions),
rather than being restricted to some well behaved meta-language.  This
is great for the programmer because the language and its library
functions is familiar, but it poses a challenge for verification
because these expressions in contracts may themselves diverge or
crash.
\item $e \in (x:\Ct_1) \rightarrow \Ct_2$ if whenever $e'$ satisfies $\Ct_1$, it
is the case that $(e\,e')$ satisfies $\Ct_2[e'/x]$.
\item $e \in \Ct_1 \& \Ct_2$ if $e$ satisfies both $\Ct_1$ and $\Ct_2$.
\item $e \in \CF$ if $e$ is \emph{crash free}, meaning that $e$ does not
crash regardless of what context it is plugged into (see Section~\ref{s:cf-fol}).
\end{itemize}

% -----------------------------------------------------------------
\section{Translating $\cal L$ to first-order logic} \label{ssect:trans-fol}

Our goal is to answer the question ``does expression $e$ satisfy
contract $C$?''.  Our plan is to translate both the expression and the
contract into first-order logic (FOL), and get a standard FOL prover
to do the heavy lifting.
In this section we formalise our new translation, and describe how we use it to
verify contracts.

\subsection{The FOL language}

\begin{figure}
\[\begin{array}{c}
\begin{array}{lrll}
\multicolumn{3}{l}{\text{Terms}} \\
  s,t & ::=  & x                          & \text{Variables} \\
      & \mid & f(\ol{t})                  & \text{Function applications} \\
      & \mid & K(\ol{t})                  & \text{Constructor applications} \\
      & \mid & \sel{K}{i}(t)              & \text{Constructor selectors} \\
      & \mid & f_{ptr} \mid app(t,s)       & \text{Pointers and application} \\
      & \mid & \unr \mid \bad             & \text{Unreachable, bad} \\ \\
\multicolumn{3}{l}{\text{Formulae}} \\
 \phi & ::=  & \lcf{t}    & \text{Crash-freedom} \\
%%      & \mid & \lncf{t}   & \text{Can provably cause crash} \\
      & \mid & t_1 = t_2  & \text{Equality} \\
      & \mid & \phi \land \phi \mid \phi \lor \phi \mid \neg \phi \\
      & \mid & \forall x @.@ \phi \mid \exists x @.@ \phi \\ \\
\end{array}
\\
\multicolumn{1}{l}{\text{Abbreviations}} \\
\begin{array}{rcl}
app(t,\oln{s}{n}) & = & (\ldots(app(t,s_1),\ldots s_n)\ldots) \\
\phi_1 \Rightarrow \phi_2 & = & \neg \phi_1 \lor \phi_2
\end{array}
\end{array}\]
\caption{Syntax of FOL}\label{fig:fol-image}
\end{figure}

We begin with the syntax of the FOL language, which is given in
Figure~\ref{fig:fol-image}. There are two syntactic forms,
\emph{terms} and \emph{formulae}. Terms include saturated function applications
$f(\ol{t})$, saturated constructor applications $K(\ol{t})$, and variables. They
also include, for each data constructor $K^\ar$ in the signature
$\Sigma$ with arity $\ar$ a set of {\em selector functions}
$\sel{K}{i}(t)$ for $i \in 1 \ldots \ar$.  The terms $app(t,s)$ and
$f_{ptr}$ concern the higher-order aspects of $\cal L$
(namely un-saturated applications), which we
discuss in Section~\ref{s:hof}.  Finally we introduce two new
syntactic constructs $\unr$ and $\bad$. As an abbreviation we often use
$app(t,\ol{s})$ for the sequence of applications to each $s_i$, as
Figure~\ref{fig:fol-image} shows.

A formula $\phi$ in Figure~\ref{fig:fol-image} is just a first-order logic
formula, augmented with a predicate $\lcf{t}$ for crash-freedom, which
we discuss in Section~\ref{s:cf-fol}.

\subsection{Translation of expressions to FOL}

% ---------------------------------------------------
\begin{figure}\small
\setlength{\arraycolsep}{2pt}
\[\begin{array}{c}
\ruleform{\ptrans{\Sigma}{P} = \formula{\phi} } \quad
\ptrans{\Sigma}{\ol{d}} = \bigwedge \ol{\dtrans{\Sigma}{d}}
\\ \\
\ruleform{\dtrans{\Sigma}{d} = \formula{\phi}} \\ \\
\begin{array}{rcl}
  \dtrans{\Sigma}{f \;\ol{a}\;\ol{(x{:}\tau)} = u}
    & =     & \formula{\forall \ol{x} @.@ \utrans{\sigma}{u}{f(\ol{x})}} \\
    & \land & \formula{\forall \ol{x} @.@ f(\ol{x}) = app(f_{ptr},\xs)} \\
\end{array}
\\ \\
\ruleform{\utrans{\Sigma}{u}{s} = \formula{\phi}} \\ \\
\begin{array}{rcl}
\utrans{\Sigma}{e}{s}
  & = & \formula{(s = \etrans{\Sigma}{\Gamma}{e})} \\
\multicolumn{3}{l}{\utrans{\Sigma}
    {@case@\;e\;@of@\;\ol{K\;\ol{y} -> e'}}{s}} \\
\multicolumn{3}{l}{
\quad
  \begin{array}[t]{rl}
    = & \formula{(t = \bad => s = bad)} \\
    \land & \formula{(\forall \ol{y} @.@ t = K_1(\ol{y}) => s = \etrans{\Sigma}{\Gamma}{e'_1})\;\land \ldots}  \\
    \land & \formula{(t{\neq}\bad\;\land\;
                 t{\neq}K_1(\oln{{\sel{K_1}{i}}(t)}{})\;\land\;\ldots => s=\unr)} \\
    \mbox{where} & t  =  \etrans{\Sigma}{\Gamma}{e}
 \end{array}
}
\end{array}
\\ \\
\ruleform{\etrans{\Sigma}{\Gamma}{e} = \formula{t} } \\ \\
\begin{array}{rcl}
\etrans{\Sigma}{\Gamma}{x} & = & \formula{x} \\
\etrans{\Sigma}{\Gamma}{f[\ol{\tau}]} & = & \formula{f_{ptr}} \\
\etrans{\Sigma}{\Gamma}{K[\ol{\tau}](\ol{e})} & = & \formula{K(\ol{\etrans{\Sigma}{\Gamma}{e}})} \\
\etrans{\Sigma}{\Gamma}{e_1\;e_2} & = & \formula{app(\etrans{\Sigma}{\Gamma}{e_1},
                                                     \etrans{\Sigma}{\Gamma}{e_2})} \\
\etrans{\Sigma}{\Gamma}{@BAD@} & = & \formula{\bad}
\end{array}
\\ \\
\ruleform{\ctrans{\Sigma}{\Gamma}{e \in \Ct} = \formula{\phi}} \\ \\
\begin{array}{rcl}
\ctrans{\Sigma}{\Gamma}{e \in \{(x{:}\tau) \mid e' \}}
  & = & \formula{t{=}\unr} \\
  & \lor & \formula{t'[t/x]{=}\unr} \\
  & \lor & \formula{t'[t/x]{=}\True} \\
  & \mbox{where} &
    \begin{array}[t]{rcl}
      t  & = & \etrans{\Sigma}{\Gamma}{e} \; \text{and} \; t' = \etrans{\Sigma}{\Gamma}{e'}
    \end{array}
\\
\ctrans{\Sigma}{\Gamma}{e \in (x{:}\Ct_1) -> \Ct_2}
  & = & \formula{\forall x @.@ \ctrans{\Sigma}{\Gamma,x}{x \in \Ct_1}
                          \Rightarrow \ctrans{\Sigma}{\Gamma,x}{e\;x \in \Ct_2}}
\\
\ctrans{\Sigma}{\Gamma}{e \in \Ct_1 \& \Ct_2}
   & = & \formula{ \ctrans{\Sigma}{\Gamma}{e \in \Ct_1} /\ \ctrans{\Sigma}{\Gamma}{e \in \Ct_2}}
\\
\ctrans{\Sigma}{\Gamma}{e \in \CF} & = & \formula{\lcf{\etrans{\Sigma}{\Gamma}{e}}}
\end{array}
\end{array}\]
\caption{Translation of programs and contracts to logic}
   \label{fig:etrans}\label{fig:contracts-minless}
\end{figure}
% ---------------------------------------------------
\begin{figure}\small
\setlength{\arraycolsep}{1pt}
\[\begin{array}{c}
\ruleform{\text{Theory}\,\Th} \\
\begin{array}{ll}
\multicolumn{2}{l}{\text{Axioms for $bad$ and $unr$}} \\
 \textsc{AxAppBad}  & \formula{\forall x @.@ app(\bad,x){=}\bad}  \\
 \textsc{AxAppUnr}  & \formula{\forall x @.@ app(\unr,x){=}\unr}    \\
 \textsc{AxDisjBU} & \formula{\bad \neq \unr}  \\
\\
\multicolumn{2}{l}{\mbox{Axioms for data constructors}} \\
 \textsc{AxDisjC} & \formula{\forall \oln{x}{n}\oln{y}{m} @.@ K(\ol{x}) \neq J(\ol{y})} \\
                  & \text{ for every } (K{:}\forall\as @.@ \oln{\tau}{n} -> T\;\as) \in \Sigma \\
                  & \text{ and } (J{:}\forall\as @.@ \oln{\tau}{m} -> S\;\as) \in \Sigma \\
 \textsc{AxDisjCBU} & \formula{(\forall \oln{x}{n} @.@ K(\ol{x}) \neq \unr \; \land \; K(\ol{x}) \neq \bad)} \\
                  & \text{ for every } (K{:}\forall\as @.@ \oln{\tau}{n} -> T\;\as) \in \Sigma \\
 \textsc{AxInj}   & \formula{\forall \oln{y}{n} @.@ \sel{K}{i}(K(\ys)) = y_i} \\
                  & \text{for every } K^\ar \in \Sigma \text{ and } i \in 1..n \\
\\
\multicolumn{2}{l}{\mbox{Axioms for crash-freedom}} \\
 \textsc{AxCfC}  & \formula{\forall \oln{x}{n} @.@ \lcf{K(\ol{x})} <=> \bigwedge\lcf{\ol{x}}} \\
                 & \text{ for every } (K{:}\forall\as @.@ \oln{\tau}{n} -> T\;\as) \in \Sigma \\
 \textsc{AxCfBU} & \formula{\lcf{\unr} /\ \lncf{\bad}} \\
\end{array}
\end{array}\]
\caption{Theory $\Th$: axioms of the FOL constants}\label{fig:prelude} \label{fig:data-cons}
\end{figure}

% ---------------------------------------------------
What exactly does it mean to translate an expression to first-order logic?
We are primarily interested in reasoning about equality, so we might
hope for this informal guiding principle:

\begin{quote}
If we can prove in FOL that $\etrans{}{}{e_1} = \etrans{}{}{e_2}$ then
$e_1$ and $e_2$ are semantically equivalent.
\end{quote}

where $\etrans{}{}{e}$ is the translation of $e$ to a FOL term. That is, we can
reason about the equality of Haskell terms by translating them into FOL, and then using
a FOL theorem prover. The formal statement of this property is Corollary~\ref{cor:guiding-principle}
\spj{Dimitrios, can you forward-ref a theorem that states this?}
\kc{This is only going to hold from right to left} \dv{Added statemnet.}

The translation of programs, definitions, and expressions to FOL
is given in Figure~\ref{fig:etrans}.
The function $\ptrans{}{P}$ translates a program to a conjunction of formulae,
one for each definition $d$, while $\dtrans{}{d}$ in turn translates
a definition $d$.
The first formula in $\dtrans{}{}$'s right-hand side invokes the translation
$\utrans{}{u}{f(\ol{x})}$ for the right hand side $u$, passing in the term $f(\ol{x})$,
and quantifying over the $\ol{x}$.  We will deal with the second formula shortly.


Ignoring @case@ for now (which we discuss in Section~\ref{s:case-fol}),
the formula $\utrans{}{e}{f(\ol{x})}$
simply asserts the equality $f(\ol{x}) = \etrans{}{}{e}$.
That is, we use a new constant $f$ in the logic for each function definition in the
program, and assert that any application of $f$ is equal to (the logical translation of)
$f$'s right hand side. Notice that we erase type arguments in the translation
since they do not affect the semantics.

Lastly $\etrans{}{}{e}$ deals with expressions.  We will deal with
functions and application next
(Section~\ref{s:hof}), but the other equations for $\etrans{}{}{e}$
are straightforward.  Notice that $\etrans{}{}{@BAD@} = bad$, and recall
that @BAD@ is the $\cal L$-term used for an inexhaustive @case@ or a call
to @error@.  It follows from our guiding principle
that for any $e$, if
$$ \etrans{}{}{e} =_F bad $$
in the logic, then the source program $e$
must be semantically equivalent to @BAD@, meaning that it definitely
crashes by calling @error@, or having an inexhaustive @case@.

\spj{We ought to say a bit more about $unr$ somewhere}

\subsection{Translating higher-order functions} \label{s:hof}

If $\cal L$ was
a first-order language the translation of function calls would be easy:
$$
\etrans{\Sigma}{\Gamma}{f[\ol{\tau}]\;\ol{e}} = \formula{f(\ol{\etrans{}{}{e}})} \\
$$
At first it might be surprising that we can also translate a \emph{higher-order} language
$\cal L$ into first order logic, but in fact it is easy to do so, as
Figure~\ref{fig:etrans} shows.  We introduce into the logic
(a) a single new constant $app$, and (b) a nullary constant $f_{ptr}$ for each function $f$
(see Figure~\ref{fig:fol-image}).
Then, the equations for $\etrans{}{}{e}$ translate application in $\cal L$ to
a use of $app$ in FOL, and any mention of function $f$ in $\cal L$ to a use
of $f_{ptr}$ in the logic.  For example:
$$
\etrans{}{}{@map f xs@} = app( app( @map@_{ptr}, @f@_{ptr}), @xs@)
$$
assuming that @map@ and @f@ are top-level functions in the $\cal L$-program, and
@xs@ is a local variable.  Once enough $app$ applications stack up, so that
$@map@_{ptr}$ is applied to two arguments, can invoke @map@ directly in the logic,
an idea we expression with the following axiom:
$$
\forall x y.\;app(app(@map@_{ptr}, x), y) = @map@(x,y)
$$
These axioms, one for each function $f$, are generated by the second
clause of the rules for $\dtrans{}{d}$ in Figure~\ref{fig:etrans}.
(The notation $app(f,\ol{x})$ is defined in Figure~\ref{fig:fol-image}.)
You can think of $@map@_{ptr}$ as a ``pointer to'', or ``name of'' of, @map@.
The $app$ axiom for @map@ translates a saturated use of @map@'s pointer into
a call of @map@ itself.

This translation of higher-order functions to first-order logic may be
easy, but it is not complete. In particular, in first-order logic we
can only reason about functions with a concrete first-order
representation (i.e. the functions that we already have and their
(partial) applications) but, for example, lambda expressions cannot be
created during proof time. Luckily, the class of properties we reason
about (contracts) never require us to do so.

\subsection{Data types and {\tt case} expressions} \label{s:case-fol}

The second equation for $\utrans{}{u}{s}$ in Figure~\ref{fig:etrans} deals with
@case@ expressions, by generating a conjunction of formulae, as follows:
\begin{itemize}
\item If the scrutinee $t$ is $bad$ (meaning that evaluating it invokes @BAD@) then
the result $s$ of the @case@ expression is also $bad$.  That is, @case@ is strict in
its scrutinee.
\item If the scrutinee is an application of one of the constructors $K_i$ mentioned
in one of the @case@ alternatives, then the result $s$ is equal to the corresponding
right-hand side, $e'_i$, after quantifying the variables $\ol{y}$ bound by the @case@ alternative.
\item Otherwise the result is $unr$.
The bit before the implication $\Rightarrow$ is just the
negation of the previous preconditions; the formula
  $t{\neq}K_1(\oln{{\sel{K}{1}}(t)}{})$
is the clumsy FOL way to say ``$t$ is not built with constructor $K_1$''.
\end{itemize}
Why do we need the last clause? Consider the function @not@:
\begin{code}
  not :: Bool -> Bool
  not True = False
  not False = True
\end{code}
Suppose we want to prove that $@not@ \in @CF@ \rightarrow @CF@$.
If we lack the last clause above, the FOL prover would have
no way to dismiss the possibility that $@not@(@3@) =_F bad$, and thus
would fail to prove the theorem.  However, the type system guarantees
that @not 3@ will never show up, and the final clause is the way we express that
fact to the FOL prover.

Of course, we also need to axiomatise the behaviour of data constructors and
selectors, which is done in Figure~\ref{fig:data-cons}:
\begin{itemize}
\item \textsc{AxDisjCBU} explains that a term headed by a data constructor cannot
also be $bad$ or $unr$.
\item \textsc{AxInj} explains how the selectors $\sel{K}{i}$ work.
\item \textsc{AxDisjC} tells the prover that all data constructors are pairwise disjoint.
There are a quadratic number of such axioms, which presents a scaling problem.
For this reason FOL provers sometimes offer a built-in notion of data constructors,
so this is not a problem in practice, but we ignore this pragmatic issue here.
\end{itemize}

\kc{Something needs to be said about recursion. Higher-order functions are not the problem, but recursive definitions are. What we get in FOL are all fixpoints, but our denotational semantics only wants least fixpoints. Luckily, many things we want to prove hold for all fixpoints, but sometimes we need to invoke induction, which is not explicitly part of the translation. Translating all this into a higher-order logic (such as Isabelle) would allow us to express that we mean the least fixpoint.}

\subsection{Translation of contracts to FOL} \label{s:contracts-fol}

Now that we know how to translate \emph{programs} to first order
logic, we turn our attention to translating \emph{contracts}.  We do
not translate a contract \emph{per se}; rather we translate the claim
$e \in \Ct$.  Once we have translated $e \in \Ct$ to a first-order logic
formula, we can ask the prover to prove it; and, if successful, we can
claim that indeed $e$ does satisfy $C$.  Of course that needs proof,
which we address in Section~\ref{s:soundness}.

Figure~\ref{fig:contracts-minless} presents the translation
$\ctrans{}{\Gamma}{e \in \Ct}$; there are four equations corresponding
to the syntax of contracts in Figure~\ref{fig:syntax}.
The last three cases are delightfully simple and direct.  Conjunction of contracts
turns into conjunction in the logic; a dependent function contract turns
into universal quantification and implication; and the claim that $e$ is
crash-free turns into a use of the special term $\lcf{t}$ in the logic.
We discuss crash-freedom in Section~\ref{s:cf-fol}.

The first equation, for predicate contracts $e \in \{(x{:}\tau) \mid e' \}$,
is sightly more complicated.
The first clause $t=unr$ says that the contract holds if $e$ diverges \spj{Is this right?}.
The second and third say that the contract holds if $e'$ diverges or is semantically
equal to @True@.  The choices embodied in this rule were discussed at length
in earlier work \cite{xu+:contracts} and we do not rehearse it here.

\subsection{Crash-freedom} \label{s:cf-fol}

The claim $e \in @CF@$, pronounced ``$e$ is crash-free'', means that $e$ cannot
crash \emph{regardless of context}.  So, for example @(BAD, True)@ is not crash-free
because it can crash if evaluated in the context @fst (BAD, True)@.  Of course,
the context itself should not be the source of the crash; for example @(True,False)@ is
crash-free even though @BAD (True,False)@ will crash.

We use the FOL term $\lcf{t}$ to assert that $t$ is crash-free. The axioms for $\lcf{}$
are given in Figure~\ref{fig:prelude}.  \textsc{AxCfC} says that a data constructor application
is crash-free if and only iff its arguments are crash-free.  \textsc{AxCfBU} says that
$unr$ is crash-free, and that $bad$ is not.  That turns out to be all that we need.

\subsection{Summary}

That completes our formally-described --- but only informally-justified --- translation
from a $\cal L$ program and a set of contract claims, into first-order logic.
To a first approximation, we can now turn the whole formula over to a FOL prover,
and hope that it proves the assertion.

\spj{What else should we say here.  Something about recursion?  About multiple functions?}

